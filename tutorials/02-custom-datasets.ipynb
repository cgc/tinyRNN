{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446e834b",
   "metadata": {},
   "source": [
    "# Creating a custom dataset\n",
    "\n",
    "The default datasets in this repo focus on tasks with relatively few states and/or actions, like the two-step task or reversal learning tasks.\n",
    "In this notebook, we will walk through the creation of a new dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7889fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in parent directory\n",
    "import os\n",
    "if os.getcwd().split('/')[-1] != 'tinyRNN':\n",
    "    os.chdir('..')\n",
    "assert os.getcwd().split('/')[-1] == 'tinyRNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75b4c39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + '/simulating_experiments')\n",
    "sys.path.append(os.getcwd() + '/plotting_experiments')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f634b2",
   "metadata": {},
   "source": [
    "# Generating data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c15811",
   "metadata": {},
   "source": [
    "## Make a task\n",
    "\n",
    "Here, we're examining a simple 5-armed Bernoulli bandit, where each arm's reward probability is sampled uniformly from $[0, 1]$. Having 5 actions is more than other tasks in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d5ea6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiArmedBandit:\n",
    "    '''5-armed Bernoulli bandit'''\n",
    "    def __init__(self, n_actions=5):\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "    def reset(self, n_trials=None):\n",
    "        self.probs = np.random.uniform(0, 1, size=self.n_actions)\n",
    "\n",
    "    def trial(self, choice):\n",
    "        outcome = np.random.binomial(1, self.probs[choice])\n",
    "        return (choice, outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a792e",
   "metadata": {},
   "source": [
    "## Initialize MF agent\n",
    "\n",
    "For our agent, we'll use a simple model-free RL agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25947b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.MABCogAgent import MABCogAgent\n",
    "\n",
    "mf = MABCogAgent(dict(cog_type='MF', n_actions=5))\n",
    "mf.model.params[mf.model.param_names.index('iTemp')] = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163b3cff",
   "metadata": {},
   "source": [
    "## Packaging data into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "51ecb626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating agent MF with params [0.5, 2.0]\n",
      "n_blocks 500 n_trials 30 sim_seed 42 sim_exp_name test additional_name \n",
      "[3 0 1 1 3 2 3 0 1 0 1 1 0 1 2 1 1 2 2 0 2 2 1 1 4 1 1 1 2 1]\n",
      "[1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from simulating_experiments.simulate_experiment import simulate_exp\n",
    "config = dict(\n",
    "    n_blocks=500, n_trials=30, sim_seed=42, sim_exp_name='test', additional_name='',\n",
    "    task='BartoloMonkey',\n",
    ")\n",
    "data = simulate_exp(mf, MultiArmedBandit(), config, save=False)\n",
    "\n",
    "print(data['action'][0])\n",
    "print(data['reward'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a836d01",
   "metadata": {},
   "source": [
    "We take just the essential data fields, for the purpose of this example. It's a bit clumsy, but one way to get this dataset loading to work is to first write out our data in its format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "16d522d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files/SimpleDataset/5ab-mf.pkl']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "fn = 'files/SimpleDataset/5ab-mf.pkl'\n",
    "joblib.dump({\n",
    "    'action': data['action'],\n",
    "    'reward': data['reward'],\n",
    "}, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5644df7",
   "metadata": {},
   "source": [
    "Now we can check to see whether the dataset loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4674dd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((3, 4, 5))\n",
    "\n",
    "items = np.array([0, 2, 3], dtype=int)\n",
    "x[0, items, 0] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "11d07adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batch size: 500\n",
      "actions are encoded properly\n",
      "[3 0 1 1 3 2 3 0 1 0]\n",
      "tensor([3, 0, 1, 1, 3, 2, 3, 0, 1, 0])\n",
      "rewards are encoded properly\n",
      "[1 0 1 1 0 1 0 1 1 0]\n",
      "tensor([1., 0., 1., 1., 0., 1., 0., 1., 1., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from datasets.dataset_utils import Dataset\n",
    "behav_data_spec = {\n",
    "    'data': fn,\n",
    "    'input_format': [\n",
    "        dict(name='action', one_hot_classes=5),\n",
    "        dict(name='reward'),\n",
    "    ],\n",
    "    'output_dim': 5, # number of output dimensions\n",
    "    'target_name': 'action',\n",
    "}\n",
    "dd = Dataset('Simple', behav_data_spec=behav_data_spec)\n",
    "dd.behav_to(dict(behav_format='tensor', output_h0=True))\n",
    "\n",
    "print('actions are encoded properly')\n",
    "print(data['action'][0][:10])\n",
    "print(dd.torch_beahv_input[:, 0, :5][:10].max(1).indices)\n",
    "\n",
    "print('rewards are encoded properly')\n",
    "print(data['reward'][0][:10])\n",
    "print(dd.torch_beahv_input[:, 0, 5][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc6cda",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Note: this will take a few minutes! But subsequent executions will load saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ac9e625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existing  D:\\cognitive_dynamics\\saved_model/5ab_mf/hidden_dim-2/allfold_summary.pkl\n",
      "Already existing  D:\\cognitive_dynamics\\saved_model/5ab_mf/hidden_dim-5/allfold_summary.pkl\n"
     ]
    }
   ],
   "source": [
    "from training_experiments.training import behavior_cv_training_config_combination\n",
    "\n",
    "base_config = {\n",
    "      ### dataset info\n",
    "      'dataset': 'Simple',\n",
    "      'behav_data_spec': behav_data_spec,\n",
    "\n",
    "      ### model info\n",
    "      'behav_format': 'tensor',\n",
    "      'agent_type': 'RNN',\n",
    "      'rnn_type': 'GRU', # which rnn layer to use\n",
    "      'include_embedding': False,\n",
    "      'input_dim': 6,\n",
    "      'hidden_dim': 2, # dimension of this rnn layer\n",
    "      'output_dim': 6, # dimension of action\n",
    "      'output_h0': True, # whether initial hidden state included in loss\n",
    "      'trainable_h0': False, # the agent's initial hidden state trainable or not\n",
    "      'readout_FC': True, # whether the readout layer is full connected or not\n",
    "      'one_hot': False, # whether the data input is one-hot or not\n",
    "\n",
    "      'device': 'cpu',\n",
    "      ### training info for one model\n",
    "      'lr': 0.005,\n",
    "      'l1_weight': 1e-5,\n",
    "      'weight_decay': 0,\n",
    "      'penalized_weight': 'rec',\n",
    "      'max_epoch_num': 10000,\n",
    "      'early_stop_counter': 200,\n",
    "      'batch_size': 0, # no mini-batch\n",
    "      ### training info for many models on dataset\n",
    "      'outer_splits': 3,\n",
    "      'inner_splits': 2,\n",
    "      'single_inner_fold': True,\n",
    "      'seed_num': 1,\n",
    "\n",
    "      ### additional training info\n",
    "      'save_model_pass': 'minimal', # 'full' for saving all results; 'minimal' for saving only the losses; 'none' for not saving results\n",
    "      'training_diagnose': [], # can be a list of diagnose function strings\n",
    "\n",
    "      ### current training exp path\n",
    "      'exp_folder': '5ab_mf',\n",
    "}\n",
    "\n",
    "config_ranges = { # keys are used to generate model names\n",
    "  'hidden_dim': [2,5],\n",
    "}\n",
    "\n",
    "behavior_cv_training_config_combination(base_config, config_ranges, n_jobs=1, verbose_level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad5895c",
   "metadata": {},
   "source": [
    "# Identify best models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c33620d",
   "metadata": {},
   "source": [
    "For comparison, we also log the likelihood of the data under the generating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "998ee5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average log likelihood of generated data -1.4120364328282298\n"
     ]
    }
   ],
   "source": [
    "ll = np.mean(np.concat([\n",
    "    row['trial_log_likelihood']\n",
    "    for row in data['mid_vars']\n",
    "]))\n",
    "print('average log likelihood of generated data', ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9f3c8596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Select best models based on inner_fold_perf_key: trainval_loss exp_folder: 5ab_mf\n",
      "Searching for summary files...\n",
      "Found 2 summary files.\n",
      "Filtering by {'agent_type': 'RNN'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 875.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ab_mf/hidden_dim-2/outerfold0_innerfold0_seed0\n",
      "Total batch size: 500\n",
      "Warning: no trial_type in the loaded data, set to -1\n",
      "5ab_mf/hidden_dim-2/outerfold1_innerfold0_seed0\n",
      "Warning: no trial_type in the loaded data, set to -1\n",
      "5ab_mf/hidden_dim-2/outerfold2_innerfold0_seed0\n",
      "Warning: no trial_type in the loaded data, set to -1\n",
      "5ab_mf/hidden_dim-5/outerfold0_innerfold0_seed0\n",
      "Warning: no trial_type in the loaded data, set to -1\n",
      "5ab_mf/hidden_dim-5/outerfold1_innerfold0_seed0\n",
      "Warning: no trial_type in the loaded data, set to -1\n",
      "5ab_mf/hidden_dim-5/outerfold2_innerfold0_seed0\n",
      "Warning: no trial_type in the loaded data, set to -1\n",
      "   block  test_loss  trainval_loss  train_loss  val_loss  test_acc  trainval_acc  train_acc   val_acc  hidden_dim rnn_type  readout_FC distill pretrained distill_temp teacher_prop agg_outer_fold                                                 agg_test_loss  total_test_loss  test_trial_num  total_trainval_loss  trainval_trial_num  total_train_loss  train_trial_num  total_val_loss  val_trial_num  test_loss_outer_std  test_loss_outer_sem  mean_train_trial_num  mean_val_trial_num                                                    agg_test_acc  total_test_acc  total_trainval_acc  total_train_acc  total_val_acc  test_acc_outer_std  test_acc_outer_sem  test_loss_mean_inner_sem  test_loss_outer_inner_sem  test_acc_mean_inner_sem  test_acc_outer_inner_sem\n",
      "0     -1   1.521243       1.510412    1.499205  1.521575  0.345933      0.357633   0.361790  0.353493           2      GRU        True    none       none         none         none      [0, 1, 2]   [1.5353426827193515, 1.518269495497033, 1.5100498871728198]     22818.645451         15000.0         45312.373246             30000.0      22443.101425          14970.0    22869.271821        15030.0             0.012902             0.007449                4990.0              5010.0    [0.3395209580838323, 0.3520958083832335, 0.3461847389558233]          5189.0             10729.0           5416.0         5313.0            0.006291            0.003632                       NaN                   0.007449                      NaN                  0.003632\n",
      "1     -1   1.465703       1.449537    1.435712  1.463308  0.393933      0.403367   0.410955  0.395808           5      GRU        True    none       none         none         none      [0, 1, 2]  [1.4783739196734955, 1.4695259744823088, 1.4491110074669276]     21985.551287         15000.0         43486.120686             30000.0      21492.608394          14970.0    21993.512292        15030.0             0.015008             0.008665                4990.0              5010.0  [0.38003992015968063, 0.3934131736526946, 0.40843373493975904]          5909.0             12101.0           6152.0         5949.0            0.014205            0.008201                       NaN                   0.008665                      NaN                  0.008201\n",
      "Estimated dimensionality:\n",
      "   block rnn_type  hidden_dim  less_than_former  test_loss less_pvalue\n",
      "0     -1      GRU           2                 1   1.521243  [1.0, 1.0]\n",
      "1     -1      GRU           5                 1   1.465703  [0.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/carlos/pd/tinyRNN/agents/RNNAgent.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_SAVE_PATH / model_path / 'model.ckpt', map_location=torch.device(self.config['device']))\n",
      "/Users/carlos/pd/tinyRNN/agents/RNNAgent.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_SAVE_PATH / model_path / 'model.ckpt', map_location=torch.device(self.config['device']))\n",
      "/Users/carlos/pd/tinyRNN/agents/RNNAgent.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_SAVE_PATH / model_path / 'model.ckpt', map_location=torch.device(self.config['device']))\n",
      "/Users/carlos/pd/tinyRNN/agents/RNNAgent.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_SAVE_PATH / model_path / 'model.ckpt', map_location=torch.device(self.config['device']))\n",
      "/Users/carlos/pd/tinyRNN/agents/RNNAgent.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_SAVE_PATH / model_path / 'model.ckpt', map_location=torch.device(self.config['device']))\n",
      "/Users/carlos/pd/tinyRNN/agents/RNNAgent.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_SAVE_PATH / model_path / 'model.ckpt', map_location=torch.device(self.config['device']))\n"
     ]
    }
   ],
   "source": [
    "from analyzing_experiments.analyzing_perf import find_best_models_for_exp\n",
    "\n",
    "exp_folder = '5ab_mf'\n",
    "find_best_models_for_exp(\n",
    "    exp_folder, 'MABCog',\n",
    "    additional_rnn_keys={'model_identifier_keys': ['block','distill','pretrained', 'distill_temp','teacher_prop',],},\n",
    "    rnn_sort_keys=['block', 'hidden_dim'],\n",
    "    has_rnn=True,\n",
    "    has_cog=False,\n",
    "    return_dim_est=True,\n",
    "    include_acc=True,\n",
    "    check_missing=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c776a72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
